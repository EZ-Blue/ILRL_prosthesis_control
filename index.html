<!DOCTYPE html>
<html>
<head>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
  <meta charset="utf-8">
  <meta name="description"
        content="A Comparative Study of Imitation and Reinforcement Learning for Transtibial Prosthesis Control in Physics-Informed Locomotion Simulations">
  <meta name="keywords" content="Prosthetics, Exoskeletons, Reinforcement Learning, Imitation Learning, Locomotion, Controls">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>A Comparative Study of Imitation and Reinforcement Learning for Transtibial Prosthesis Control in Physics-Informed Locomotion Simulations</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=YOUR-GA-ID"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'YOUR-GA-ID');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/symbol.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">A Comparative Study of Imitation and Reinforcement Learning for Transtibial Prosthesis Control in Physics-Informed Locomotion Simulations</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/jonathan-he-628493248/">Jonathan (Jintong) He</a><sup>1<sup>*</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/shawnkrishnan/">Shawn Krishnan</a><sup>1<sup>*</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/manuellancastre/">Manuel Lancastre</a><sup>1<sup>*</sup>,
            </span>
            <span class="author-block">
              <a href="https://ez-blue.github.io/">Eric Zhao</a><sup>1<sup>*</sup>,
            </span>
            <span class="author-block">
              <a href="https://inseungkang.github.io/">Inseung Kang</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Mechanical Engineering, Carnegie Mellon University</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Equal Contributions</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="static/pdfs/24782_Phase_2_Project_Report__IEEE_Conference_Template_ (2).pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              <!-- </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/YOUR-PAPER-ID"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/JintongHe/AIE_Project_Team1"
                   class="external-link button is-normal is-rounded is-dark" target="_blank">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser"></section>
  <div class="container is-max-desktop">
    <div class="has-text-centered">
      <div class="columns is-centered">
        <div class="column is-full">
          <video controls autoplay muted loop playsinline style="width: 100%;">
            <source src="static/videos/teaser.mp4" type="video/mp4">
            <!-- Fallback message -->
            Your browser does not support the video tag.
          </video>
          <h2 class="subtitle has-text-centered">
            <span class="dnerf"></span> Our Imitation and Reinforcement Learning models enable adaptable control of transtibial assistive devices.
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Individuals with lower extremity impairments often face significant mobility challenges, as current control strategies for transtibial prostheses and exoskeletons may not be adequately adapted to varied environments and user-specific needs. Traditional control methods, such as finite-state machines and impedance control, can be limited in their ability to handle the dynamic and complex nature of human locomotion. To address these limitations, our research explores the application of deep learning techniques to control transtibial prostheses and exoskeletons to improve mobility for individuals with lower extremity limitations. We compare imitation learning (IL) and deep reinforcement learning (RL) approaches to develop adaptive control policies for ankle assistive devices, and evaluate their produced locomotion performance against expert human locomotion models. Using the Mujoco physics engine and Loco-Mujoco framework, we implemented a two-agent imitation learning framework: a Variational Adversarial Imitation Learning (VAIL) agent that controls the humanoid body and a separate agent that manages control of the ankle-level assistive device. We compared the performance of this imitation learning ankle controller to a Proximal Policy Optimization (PPO) based reinforcement learning model controller of the same ankle-level assistive device. We achieved promising results with both approaches: both the imitation learning and reinforcement learning frameworks were able to successfully produce ankle controller outputs for a transtibial prosthesis to allow a humanoid model to walk with relatively normal gait behavior. However, the imitation learning framework produced much better results, with the humanoid model able to walk much longer than the models using the reinforcement learning prosthetic controller. The imitation learning controller was also able to mimic the expert human gait cycle more accurately than the reinforcement learning model. This work demonstrates the potential of imitation and deep reinforcement learning approaches for developing adaptable, user-compatible prosthetic controllers that can function effectively across diverse environments and user conditions.          
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Methodology. -->
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered">Methodology</h2>

        <div class="content has-text-justified">
          <p>
            Our objective is to develop and evaluate an ankle prosthesis with one degree of freedom, utilizing reinforcement learning and imitation learning techniques to enable stable locomotion in the humanoid agent.          
          </p>
        </div>

        <img src="static/images/humanoid_torque_walk.gif" alt="Framework" style="width: 100%; height: auto; margin-bottom: 20px;">

        <div class="content has-text-justified">
          <p>
            For our locomotion simulation, we use the Humanoid Torque model from LocoMuJoCo, specifically the model for the walking task (there is also one for running). LocoMuJoCo has pre-trained walking models, which we use as a baseline for comparison.
          </p>
        </div>

        <img src="static/images/prosthesis diagram.png" alt="Framework" style="width: 100%; height: auto; margin-bottom: 20px;">

        <div class="content has-text-justified">
          <p>
            We altered the original humanoid model from LocoMuJoCo to implement a model with its lower right leg and foot replaced with a prosthesis, with physical parameters like inertia matching those of lower leg prosthetics we found in literature. The prosthesis model is the <a href=https://opensourceleg.org/>Open Source Leg (OSL)</a> model from University of Michigan.
          </p>
        </div>
        
        <img src="static/images/IL_framework.png" alt="Framework" style="width: 100%; height: auto; margin-bottom: 20px;">
        
        <img src="static/images/IL_rollout_diagram.png" alt="Framework" style="width: 100%; height: auto; margin-bottom: 20px;">
        <div class="content has-text-justified">
          <p>
            For imitation learning, we implement a two-agent system, where a VAIL agent is trained first using an expert dataset to teach the model how to walk, while a separate MLP-based agent manages control of the ankle-level assistive device. The MLP-based agent takes the observation space of the humanoid body's joint positions and velocities as input, and outputs a single action that represents the ankle assistive device's actuation. The MLP-based agent learns through behavior cloning by trying to minimize the error between its output action and the actual action of the expert VAIL agent given a specific observation state.
          </p>
        </div>
        
        <img src="static/images/RL_framework.png" alt="Framework" style="width: 100%; height: auto; margin-bottom: 20px;">
        <div class="content has-text-justified">
          <p>
            For reinforcement learning, we use the same approach as the imitation learning framework, except we replace the MLP-based agent with a Proximal Policy Optimization (PPO) algorithm model that takes the same observation state input and outputs an ankle prosthetic action. The PPO model tries to maximize its rewards from our provided reward function, and this leads to successful ankle action outputs and subsequent walking behavior from our humanoid prosthesis model.        
          </p>
        </div>

        <div class="content has-text-justified">
          <p>
            We experimented with 3 different observation state inputs to the IL and RL models: 36 state, 22 state and 16 state. These observation states represent a portion of the whole humanoid body observation, and we gradually limited number of inputs to mimic the limited sensor input of assistive devices in real applications, where there are typically only sensor inputs from the body parts and region near the assistive device itself. The diagrams, descriptions and LocoMuJoCo documentation for the 36, 22, and 16 observation states and their associated details can be found in the Appendix of this page.         
          </p>
        </div>
      </div>
    </div>
    <!--/ Methodology. -->

    <!-- Paper video. -->
    <div class="container is-max-desktop">
      <div class="has-text-centered">
        <h2 class="title is-3">Summary of Main Results</h2>
        <div class="columns is-centered">
          <div class="column is-full">
            <video controls style="width: 80%;">
              <source src="./static/videos/results-summary.mp4" type="video/mp4">
              <!-- Fallback message -->
              Your browser does not support the video tag.
            </video>
          </div>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>

<section class="section"> 
  <div class="container is-max-desktop">
    <div class="has-text-centered">
    <h1 class="title is-3">Comparisons to Baselines</h1>
      <h1 class="title is-4">Imitation Learning Results vs Normal Human Baseline</h1>
      <div class="columns is-centered">
        <div class="column is-half">
          <h2 class="title is-5">36-State MLP (Prosthesis) vs Normal Walking (<span style="color: green;">&#10004;</span>)</h2>
          <video controls autoplay muted loop playsinline style="width: 100%;">
            <source src="static/videos/mlp_36_128_prosthesis_combined_rollout.mp4" type="video/mp4">
          </video>
        </div>
        <div class="column is-half">
          <h2 class="title is-5">22-State MLP (Prosthesis) vs Normal Walking (<span style="color: green;">&#10004;</span>)</h2>
          <video controls autoplay muted loop playsinline style="width: 100%;">
            <source src="static/videos/mlp_22_128_prosthesis_combined_rollout.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="columns is-centered">
        <div class="column is-half">
          <h2 class="title is-5">16-State MLP (Prosthesis) vs Normal Walking (<span style="color: green;">&#10004;</span>)</h2>
          <video controls autoplay muted loop playsinline style="width: 100%;">
            <source src="static/videos/mlp_16_128_prosthesis_combined_rollout.mp4" type="video/mp4">
          </video>
        </div>
        <div class="column is-half">
          <h2 class="title is-5">Normal Human Baseline (No Prosthesis) (<i class="fas fa-times" style="color: red;"></i>)</h2>
          <video controls autoplay muted loop playsinline style="width: 100%;">
            <source src="static/videos/normal_walking.mov" type="video/quicktime">
          </video>
        </div>
      </div>
    </div>
  </div>
  <br><br><br>
  <div class="container is-max-desktop">
    <div class="has-text-centered">
      <h1 class="title is-4">Reinforcement Learning Results vs Normal Human Baseline</h1>
      <div class="columns is-centered">
        <div class="column is-half">
          <h2 class="title is-5">36-State PPO (Prosthesis) vs Normal Walking (<span style="color: green;">&#10004;</span>)</h2>
          <video controls autoplay muted loop playsinline style="width: 100%;">
            <source src="static/videos/RL_36_128_prosthesis_combined_rollout.mp4" type="video/mp4">
          </video>
        </div>
        <div class="column is-half">
          <h2 class="title is-5">22-State PPO (Prosthesis) vs Normal Walking (<i class="fas fa-times" style="color: red;"></i>)</h2>
          <video controls autoplay muted loop playsinline style="width: 100%;">
            <source src="static/videos/RL_22_128_prosthesis_combined_rollout.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <div class="columns is-centered">
        <div class="column is-half">
          <h2 class="title is-5">16-State PPO (Prosthesis) vs Normal Walking (<i class="fas fa-times" style="color: red;"></i>)</h2>
          <video controls autoplay muted loop playsinline style="width: 100%;">
            <source src="static/videos/RL_16_128_prosthesis_combined_rollout.mp4" type="video/mp4">
          </video>
        </div>
        <div class="column is-half">
          <h2 class="title is-5">Normal Human Baseline (No Prosthesis) (<span style="color: green;">&#10004;</span>)</h2>
          <video controls autoplay muted loop playsinline style="width: 100%;">
            <source src="static/videos/normal_walking.mov" type="video/mov">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">  
  <div class="container is-max-desktop">
    <div class="has-text-centered">
      <h1 class="title is-3">Quantitative Comparisons</h1>
      <h2 class="title is-4">Timesteps Elapsed Walking</h2>
      <div class="columns is-centered">
        <div class="column is-full">
          <img src="static/images/steps_comparison.png" alt="Ankle Joint Kinematics" style="width: 80%;">
          <h3 class="title is-5">Number of Timesteps Walked Before Falling (1 timestep = 0.01 sec)</h3>
        </div>
      </div>
      <h2 class="title is-4">Ankle Joint Kinetics & Kinematics</h2>
      <div class="columns is-centered">
        <div class="column is-full">
          <img src="static/images/kinematics-kinetics comparison.png" alt="Ankle Joint Kinetics" style="width: 80%;">
          <h3 class="title is-5">MAE in Ankle Angle (°) & Moment (Nm) Compared to Expert Ground Truth Values</h3>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section"> 
  <div class="container is-max-desktop">
    <div class="has-text-centered">
      <h1 class="title is-3">Two-Agent System Implementation</h1>
      <div class="columns is-centered">
        <div class="column is-half">
          <h2 class="title is-5">Training System</h2>
          <img src="./static/images/training_system.png" alt="Training System" style="width: 90%;">
          <p>Flowchart illustrating the two-agent system used for training the humanoid model with an ankle prosthesis</p>
        </div>
        <div class="column is-half">
          <h2 class="title is-5">Evaluation System</h2>
          <img src="./static/images/evaluation_system.png" alt="Evaluation System" style="width: 90%;">
          <p>Diagram showing the evaluation of the system, demonstrating the mapping from 36 state inputs into 12 action outputs</p>
        </div>
      </div>
    </div>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="static/pdfs/24782_Phase_2_Project_Report__IEEE_Conference_Template_ (2).pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/JintongHe/AIE_Project_Team1" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>